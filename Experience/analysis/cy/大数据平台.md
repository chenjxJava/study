# 大数据平台
内容：
<pre>
客户端目录:
  3号机/usr/local/share/bigdata

hdfs://100.124.10.11:9000/

jdbc:hive2://100.124.10.11:10000/hiveomm  

spark://100.124.10.11:7077     ./spark-shell --master spark://100.124.10.11:7077

// yarn
http://100.124.10.11:8088/cluster
</pre>
### 一、hdfs

### 二、spark

### 三、hive
> hdfs-->hive

[将数据导入hive，将数据从hive导出](https://blog.csdn.net/huangge1199/article/details/78970472)

### 1.beeline连接hive
<pre>
> ./beeline
> !connect jdbc:hive2://100.124.10.11:10000/hiveomm
// 输入用户名密码，账号mr 密码ab1234

示例：
// 1.beeline
[sjksh-hm@CYZX-ZW-SJKSH-TESTSERVER-01 bin]$ ./beeline

which: no hbase in (/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/sjksh-01/lj/hive/bin:JAVA_HOME/bin:/home/sjksh-hm/.local/bin:/home/sjksh-hm/bin)
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/share/bigdata/hive/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/share/bigdata/hive/lib/spark-assembly-1.6.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/share/bigdata/hive/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Beeline version 2.1.0-zdh7.3.1 by Apache Hive

//2.连接hive,输入用户名，密码
beeline> !connect jdbc:hive2://100.124.10.11:10000/hiveomm
Connecting to jdbc:hive2://100.124.10.11:10000/hiveomm

Enter username for jdbc:hive2://100.124.10.11:10000/hiveomm: mr

Enter password for jdbc:hive2://100.124.10.11:10000/hiveomm: ******

Connected to: Apache Hive (version 2.1.0-zdh7.3.1)
Driver: Hive JDBC (version 2.1.0-zdh7.3.1)
18/10/09 15:18:28 [main]: WARN jdbc.HiveConnection: Request to set autoCommit to false; Hive does not support autoCommit=false.
Transaction isolation: TRANSACTION_REPEATABLE_READ

//3.show databases; 查询数据库
0: jdbc:hive2://100.124.10.11:10000/hiveomm> show databases

//4.use hiveoom;

//5.show tables;

//6.select * from goods;
> 
</pre>

### 四、impala



[Hadoop第4周练习—HDFS读写文件操作](https://www.cnblogs.com/shishanyuan/p/4172806.html)

五、sqoop


